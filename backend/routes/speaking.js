import express from "express";
import multer from "multer";
import fs from "fs";
import path from "path";
import { execSync } from "child_process";
import SpeakingQuestion from "../models/SpeakingQuestion.js";
import { parseSpeakingExcel } from "../utils/excelToQuestions.js";
import { transcribeAudio } from "../ai/whisper.js";
import { evaluateSpeaking } from "../ai/evaluateOpenRouter.js";

const router = express.Router();
const upload = multer({ dest: "uploads/" });

// ‚úÖ Upload ƒë·ªÅ t·ª´ Excel
router.post("/upload-speaking", upload.single("file"), async (req, res) => {
    try {
        // ‚úÖ S·ª≠a: th√™m await
        const questions = await parseSpeakingExcel(req.file.path);

        for (const q of questions) {
            console.log("‚úÖ ƒêang th√™m c√¢u h·ªèi:", q);
        }

        await SpeakingQuestion.insertMany(questions);

        res.json({ message: "‚úÖ ƒê√£ th√™m c√¢u h·ªèi Speaking", count: questions.length });
    } catch (err) {
        console.error("‚ùå L·ªói khi upload Speaking:", err);
        res.status(500).json({ error: "‚ùå L·ªói khi x·ª≠ l√Ω file Speaking" });
    }
});


// ‚úÖ L·∫•y to√†n b·ªô ƒë·ªÅ
router.get("/all", async (req, res) => {
    try {
        const questions = await SpeakingQuestion.find().sort({ part: 1 });
        res.json(questions);
    } catch (err) {
        console.error("‚ùå L·ªói l·∫•y c√¢u h·ªèi:", err);
        res.status(500).json({ message: "Kh√¥ng l·∫•y ƒë∆∞·ª£c d·ªØ li·ªáu" });
    }
});

// ‚úÖ L·∫•y random 1 c√¢u h·ªèi theo Part
router.get("/random/:part", async (req, res) => {
    try {
        const part = parseInt(req.params.part);
        const questions = await SpeakingQuestion.find({ part });
        if (questions.length === 0) return res.status(404).json({ message: "Kh√¥ng c√≥ c√¢u h·ªèi." });

        const randomQuestion = questions[Math.floor(Math.random() * questions.length)];
        res.json(randomQuestion);
    } catch (err) {
        console.error("‚ùå L·ªói random:", err);
        res.status(500).json({ message: "Kh√¥ng l·∫•y ƒë∆∞·ª£c c√¢u h·ªèi." });
    }
});

// ‚úÖ API ch·∫•m ƒëi·ªÉm Speaking (convert .webm ‚Üí .wav tr∆∞·ªõc khi g·ª≠i v√†o Whisper)
router.post("/evaluate", upload.single("audio"), async (req, res) => {
    const inputPath = req.file.path;
    const wavPath = `${inputPath}.wav`;
    const questionId = req.body.questionId;

    try {
        // üëâ Convert file .webm ‚Üí .wav
        execSync(`ffmpeg -i ${inputPath} -ar 16000 -ac 1 -c:a pcm_s16le ${wavPath}`);

        // üìò N·∫øu c√≥ questionId th√¨ l·∫•y n·ªôi dung c√¢u h·ªèi t·ª´ DB
        let expectedText = "";
        if (questionId) {
            const question = await SpeakingQuestion.findById(questionId);
            if (question) {
                if (question.text) expectedText = question.text;
                else if (question.context) expectedText = question.context;
                else if (question.questions?.length > 0) expectedText = question.questions[0];
            }
        }

        // üîà Whisper nh·∫≠n file .wav v√† n·ªôi dung c√¢u h·ªèi (n·∫øu c√≥)
        const result = await transcribeAudio(req.file.path, expectedText);
        const evaluation = await evaluateSpeaking(result.transcript);


        res.json({ transcript: result.transcript, evaluation });
    } catch (err) {
        console.error("‚ùå L·ªói evaluate:", err);
        res.status(500).json({ message: "Kh√¥ng x·ª≠ l√Ω ƒë∆∞·ª£c audio." });
    } finally {
        try {
            if (fs.existsSync(inputPath)) fs.unlinkSync(inputPath);
            if (fs.existsSync(wavPath)) fs.unlinkSync(wavPath);
        } catch (unlinkErr) {
            console.warn("‚ö†Ô∏è Kh√¥ng th·ªÉ xo√° file:", unlinkErr.message);
        }
    }
});


export default router;
